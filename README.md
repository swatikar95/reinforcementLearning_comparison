- Q-Learning algorithm took approximately 21k episodes to converge for Mountain-Car problem
- DQN took 682 episodes to converge
- Actor Critic algorithm took 56 episodes
Q-Learning is not suitable for continuous state and action space. DQN can handle continuous state but not continuous action. Actor-Critic can handle both continuous state and action space
